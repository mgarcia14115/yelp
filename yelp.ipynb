{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgarcia/.mgenv/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "splits = {'train': 'yelp_review_full/train-00000-of-00001.parquet', 'test': 'yelp_review_full/test-00000-of-00001.parquet'}\n",
    "df_train = pd.read_parquet(\"hf://datasets/Yelp/yelp_review_full/\" + splits[\"train\"])\n",
    "df_test = pd.read_parquet(\"hf://datasets/Yelp/yelp_review_full/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize data and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc( document  ):\n",
    "    \n",
    "    list_document = document.split(\" \")\n",
    "    cleaned_doc = []\n",
    "   \n",
    "    for token in list_document:\n",
    "        new_word = \"\"\n",
    "        for val in token:\n",
    "\n",
    "            if val.isalpha():\n",
    "                new_word += val.lower()               \n",
    "        if len(new_word) > 1:\n",
    "            cleaned_doc.append(new_word)\n",
    "\n",
    "    \n",
    "    return cleaned_doc\n",
    "\n",
    "df_train[\"cleaned_text\"] = df_train[\"text\"].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab and Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_vocab(lexicon):\n",
    "    vocab = {}\n",
    "    index = 0\n",
    "\n",
    "    for word in lexicon:\n",
    "\n",
    "        vocab[word] = index\n",
    "        index+=1\n",
    "\n",
    "    return vocab\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_lexicon():\n",
    "    lexicon = set({ })\n",
    "\n",
    "    for document in df_train[\"cleaned_text\"]:\n",
    "        for word in document:\n",
    "            lexicon.add(word)\n",
    "\n",
    "\n",
    "    \n",
    "    return lexicon\n",
    "\n",
    "\n",
    "\n",
    "lexicon = get_lexicon()\n",
    "vocab = get_vocab(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model, Dataset, and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class FFNN(nn.Module):\n",
    "\n",
    "    def __init__(self , vocab_size , embedding_size, hidden_layer ,classes):\n",
    "        super(FFNN,self).__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.linear1 = nn.Linear(embedding_size , hidden_layer)\n",
    "        self.linear2 = nn.Linear( hidden_layer , classes )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.embeddings(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class customDataset( Dataset ):\n",
    "\n",
    "    def __init__ ( self, X , Y):\n",
    "\n",
    "        self.x = torch.tensor(X)\n",
    "        self.y = torch.tensor(Y)\n",
    "\n",
    "\n",
    "    def __len__( self ):\n",
    "\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self , idx):\n",
    "\n",
    "\n",
    "        return self.x[idx],self.y[idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OHE documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_document( document ):\n",
    "    ohe_doc = []\n",
    "    for word in document:\n",
    "        ohe_doc.append( vocab[word] )\n",
    "\n",
    "    return torch.tensor(ohe_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"ohe_doc\"] = df_train[\"cleaned_text\"].apply(ohe_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pad documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = pad_sequence(df_train[\"ohe_doc\"], batch_first=True ,padding_value=0.0) \n",
    "Y_train = torch.tensor(df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFNN( len(vocab) , 100 , 100 , len(df_train[\"label\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mgenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
